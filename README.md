# LLM Learning Notes

本仓库用于记录学习机器学习中的笔记，分享面试经验

[🇨🇳 中文](./README.md) | [🇺🇸 English](./README_EN.md)

Email:kerwinish@gmail.com

🚩最近更新 10/24/2025

## 目录
```
LLM_NOTE/
├── DecisionTree/
│   ├── DecisionTreeCn.md
│   └── DecisionTreeEn.md
│
├── Essay_reading/
│   ├── Bert_note_cn.md
│   ├── Bert_note_en.md
│   └── Bert.pdf
│
├── images/
│   ├── GLU.jpg
│   └── SwiGLU.jpg
│
├── lora/
│   ├── LoRA&QLoRAHyperparameterConfiguration.md
│   ├── lora微调.pdf
│   └── lora微调的参数怎么选择，lora和Qlora的区别.md
│
├── tokenizer/
│   ├── Tokenlizer_cn.md
│   └── Tokenlizer_en.md
│
├── UserPromptAndSystemPrompt/
│   ├── What's_user_prompt_and_system_prompt_cn.md
│   └── What's_user_prompt_and_system_prompt_en.md
│
├── WhyLayerNormInTransformer/
│   ├── Transformer中为什么使用LayerNorm而不是BatchNorm.md
│   └── WhyLayerNormInTransformer.md
│
├── LICENSE
├── MLA_in_Deepseekv2.md
├── README_EN.md
├── README.md
├── 什么是激活函数，常见的激活函数有哪些.md
├── 归一化和标准化.md
└── 面试问题整理.md
```


## 文件分类说明

| 分类 | 内容简介 |
|------|-----------|
| **DecisionTree** | 决策树相关概念、实现与可视化笔记 |
| **Essay_reading** | 学术论文阅读笔记（如BERT） |
| **images** | 配图资源（GLU、SwiGLU等） |
| **lora** | LoRA与QLoRA微调方法与参数选择 |
| **tokenizer** | 分词器原理与中英文实现说明 |
| **UserPromptAndSystemPrompt** | 用户提示与系统提示机制探究 |
| **WhyLayerNormInTransformer** | Transformer中LayerNorm的设计原因 |
| **其他单文件笔记** | 激活函数、归一化、面试题整理等 |

---

##  学习方向
- Transformer架构原理与优化  
- 参数高效微调（PEFT / LoRA / QLoRA）  
- Tokenizer机制与Prompt设计  
- 机器学习算法基础与数值稳定性  

---

##  贡献 & 使用
欢迎提出改进建议或提交Pull Request。  
Feel free to contribute or reuse notes with attribution under the LICENSE file.