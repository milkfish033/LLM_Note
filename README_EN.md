# LLM Learning Notes

This repository is for recording notes during the learning process of **Large Language Models (LLMs)**.  

[ðŸ‡¨ðŸ‡³ ä¸­æ–‡](./README.md) | [ðŸ‡ºðŸ‡¸ English](./README_EN.md)

Email: kerwinish@gmail.com

ðŸš© Latest Update: 10/10/2025

## Table of Contents

1. Tokenizer  
2. What is an activation function, and what types of activation functions are there  
3. LayerNorm  
4. MLA in Deepseek v2  
5. Why Transformer uses LayerNorm instead of BatchNorm  
6. LoRA fine-tuning (Qwen-based with LLaMA Factory)  
7. How to choose LoRA fine-tuning parameters and what is the difference between LoRA and QLoRA
